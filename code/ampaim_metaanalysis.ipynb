{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7bc565-0ef1-4d28-8bb1-e71b9676b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import statsmodels.stats.multitest\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# disable warnings, use w caution\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# project specific libs\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c9485e-950d-494d-a210-9a5e772dfdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project specific path\n",
    "path = '/Users/KevinBu/Desktop/clemente_lab/Projects/ampaim/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6600049e-0662-4fd7-833b-019e40918e0d",
   "metadata": {},
   "source": [
    "##### Meta Analyses Setup #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5249e5a-2861-4438-a0f6-382d9cae895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define replacements prior to analysis\n",
    "sub_dict=  {'healthy control': 'HC',\n",
    "            'healthy': 'HC',\n",
    "            'Healthy': 'HC',\n",
    "            'HLT': 'HC',\n",
    "            'NORA':'RA',\n",
    "            'SLE-G': 'SLE',\n",
    "            'axial spondyloarthritis': 'axSpA',\n",
    "            'sle': 'SLE',\n",
    "            'ss': 'SjD',\n",
    "            'psa': 'PsA',\n",
    "            'pso': 'PsO',\n",
    "            'nss': 'NSS',\n",
    "            'pSS patients without treament': 'SjD'\n",
    "           }\n",
    "\n",
    "dx_sub_dict = {'host_disease':'Diagnosis'}\n",
    "\n",
    "jobs = ['jobs09','jobs10','jobs12','jobs13','jobs41','jobs44','jobs45','jobs46','jobs49']\n",
    "\n",
    "\n",
    "### all data\n",
    "j_to_res = {\n",
    "    'jobs09': {\n",
    "        'Diagnosis': 'RA',\n",
    "        'Cohort': 'AMPAIM',\n",
    "        'LEfSe_path': '/Users/KevinBu/Desktop/clemente_lab/Projects/ampaim/outputs/jobs09/lefse_results.res'\n",
    "    },\n",
    "    'jobs10':{\n",
    "        'Diagnosis': 'PsO',\n",
    "        'Cohort': 'AMPAIM',\n",
    "        'LEfSe_path': '/Users/KevinBu/Desktop/clemente_lab/Projects/ampaim/outputs/jobs10/lefse_results.res'\n",
    "    },\n",
    "    'jobs11':{\n",
    "        'Diagnosis': 'PsA',\n",
    "        'Cohort': 'AMPAIM',\n",
    "        'LEfSe_path': '/Users/KevinBu/Desktop/clemente_lab/Projects/ampaim/outputs/jobs11/lefse_results.res'\n",
    "    },\n",
    "    'jobs12':{\n",
    "        'Diagnosis': 'SjD',\n",
    "        'Cohort': 'AMPAIM',\n",
    "        'LEfSe_path': '/Users/KevinBu/Desktop/clemente_lab/Projects/ampaim/outputs/jobs12/lefse_results.res'\n",
    "    },\n",
    "    'jobs13':{\n",
    "        'Diagnosis': 'SLE',\n",
    "        'Cohort': 'AMPAIM',\n",
    "        'LEfSe_path': '/Users/KevinBu/Desktop/clemente_lab/Projects/ampaim/outputs/jobs13/lefse_results.res'\n",
    "    },\n",
    "    'jobs14':{\n",
    "        'Diagnosis': 'NSS',\n",
    "        'Cohort': 'AMPAIM',\n",
    "        'LEfSe_path': '/Users/KevinBu/Desktop/clemente_lab/Projects/ampaim/outputs/jobs14/lefse_results.res'\n",
    "    },\n",
    "    'jobs41':{\n",
    "        'Diagnosis': 'SLE',\n",
    "        'Cohort': 'Su2020',\n",
    "        'LEfSe_path': path + 'outputs/jobs41/Analysis_lefse_0/results/Diagnosis/lefse_results.taxa_table_L7.Diagnosis-HC-or-SLE-G.Diagnosis.NA.tsv'\n",
    "    },\n",
    "    'jobs43':{\n",
    "        'Diagnosis': 'AxSpA',\n",
    "        'Cohort': 'Gill2022',\n",
    "        'LEfSe_path': path + 'outputs/jobs43/Analysis_lefse_0/results/Diagnosis/lefse_results.taxa_table_L7.Diagnosis.NA.tsv'\n",
    "    },\n",
    "    'jobs44':{\n",
    "        'Diagnosis': 'SjD',\n",
    "        'Cohort': 'Wang2022',\n",
    "        'LEfSe_path': path + 'outputs/jobs44/Analysis_lefse_0/results/Diagnosis/lefse_results.taxa_table_L7.Diagnosis.NA.tsv'\n",
    "    },\n",
    "    'jobs45':{\n",
    "        'Diagnosis': 'PsO',\n",
    "        'Cohort': 'Luca2024',\n",
    "        'LEfSe_path': path + 'outputs/jobs45/Analysis_lefse_0/results/Diagnosis/lefse_results.taxa_table_L7.Diagnosis.NA.tsv'\n",
    "    },\n",
    "    'jobs46':{\n",
    "        'Diagnosis': 'RA',\n",
    "        'Cohort': 'Yu2022',\n",
    "        'LEfSe_path': path + 'outputs/jobs46/Analysis_lefse_0/results/Diagnosis/lefse_results.taxa_table_L7.Diagnosis.NA.tsv'\n",
    "    },\n",
    "    'jobs49':{\n",
    "        'Diagnosis': 'RA',\n",
    "        'Cohort': 'Rooney2024',\n",
    "        'LEfSe_path': path + 'outputs/jobs49/Analysis_lefse_0/results/Diagnosis/lefse_results.taxa_table_L7.Diagnosis.NA.tsv'\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afabff3-aff2-4a83-9f9a-baf027b37926",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Process LEfSe results prior to UpSetR #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1082c018-99f3-4809-bd50-0f52a2f3f60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# for AMPAIM\n",
    "\n",
    "for j in jobs:\n",
    "    # grab res dict\n",
    "    res = j_to_res[j]\n",
    "\n",
    "    # grab df and name columns\n",
    "    if '.res' in res['LEfSe_path']:\n",
    "        header = None\n",
    "    elif '.taxa' in res['LEfSe_path']:\n",
    "        header = 0\n",
    "    \n",
    "    df_lefse = pd.read_csv(res['LEfSe_path'], sep='\\t', header=header, names =['Taxa','X','Direction','LDA','p'])\n",
    "   \n",
    "    # drop na\n",
    "    df_lefse = df_lefse[df_lefse['p'] != '-']\n",
    "    \n",
    "    # cast to float\n",
    "    df_lefse['p'] = df_lefse['p'].astype(float)\n",
    "\n",
    "    # filter on NA \n",
    "    df_lefse = df_lefse[~np.isnan(df_lefse['LDA'])]\n",
    "\n",
    "    # save\n",
    "    for d in df_lefse.Direction.unique():    \n",
    "        df = df_lefse[df_lefse['Direction'] == d] \n",
    "        df.to_csv(path + 'outputs/jobs100/' + res['Cohort'] + '_' + res['Diagnosis'] + '_' + d + '.tsv', sep='\\t')\n",
    "        \n",
    "\n",
    "#df = df[np.isnan(df['LDA'])]\n",
    "#LDAnan = df.Taxa.values\n",
    "\n",
    "# print(LDAnan)\n",
    "print(len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47ce70b-dca4-4c51-a5a3-6bbfc9ad48ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### jobs39 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f389e19-efd3-47df-83c0-7c80b995c261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#SampleID', 'LinkerPrimerSequence', 'BarcodeSequence',\n",
       "       'Assay Type', 'AvgSpotLen', 'Bases', 'BioProject', 'BioSample',\n",
       "       'BioSampleModel', 'Bytes', 'Center Name', 'collection_date',\n",
       "       'Consent', 'DATASTORE filetype', 'DATASTORE provider',\n",
       "       'DATASTORE region', 'Experiment', 'geo_loc_name_country',\n",
       "       'geo_loc_name_country_continent', 'geo_loc_name', 'host',\n",
       "       'Instrument', 'isolation_source', 'lat_lon', 'Library Name',\n",
       "       'LibraryLayout', 'LibrarySelection', 'LibrarySource', 'Organism',\n",
       "       'Platform', 'ReleaseDate', 'create_date', 'version', 'Sample Name',\n",
       "       'SRA Study', '1-Methylhistidine', '3-Methylhistidine', 'Alanine',\n",
       "       'allo-Isoleucine', 'alpha-Amino-N-butyric-acid',\n",
       "       'alpha-Aminoadipic-acid', 'Anserine', 'Arginine', 'Asparagine',\n",
       "       'Aspartic_Acid', 'beta-Alanine', 'beta-Aminoisobutyric-acid',\n",
       "       'betaine', 'carnitine', 'Carnosine', 'choline', 'Citrulline',\n",
       "       'Cystathionine_1', 'Cystathionine_2', 'Cystine', 'Ethanolamine',\n",
       "       'gamma-Amino-N-butyric-acid', 'Glutamic_Acid', 'Glutamine',\n",
       "       'Glycine', 'Histidine', 'Homocystine', 'Hydroxylysine_1',\n",
       "       'Hydroxylysine_2', 'Hydroxyproline', 'Isoleucine', 'Leucine',\n",
       "       'Lysine', 'Methionine', 'Ornithine', 'Phenylalanine',\n",
       "       'Phosphoethanolamine', 'proline', 'Sarcosine', 'Serine', 'Taurine',\n",
       "       'Threonine', 'tma', 'TMAO', 'Tryptophan', 'Tyrosine', 'Valine',\n",
       "       'ACPA', 'bmi', 'CRP', 'Eggerthella', 'gender', 'Global', 'HAQ',\n",
       "       'HLADR4', 'Hydroxychloroquine', 'Methotrexate', 'prednisone',\n",
       "       'RadiographicErosions', 'relation', 'rf', 'symptoms'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jobs39 is where the first PRJNA will be tested, 16S sequencing\n",
    "# PRJNA317370\n",
    "# we need to generate a Q2 mapping file like in OA\n",
    "q2_oa = pd.read_csv(path + 'outputs/jobs39/oaq2.tsv', sep='\\t')\n",
    "\n",
    "# take columns i think we need\n",
    "keep = ['BarcodeSequence','LinkerPrimerSequence']\n",
    "\n",
    "# grab sample IDs\n",
    "# df_map = q2_oa.loc[:,keep]\n",
    "\n",
    "df_sra = pd.read_csv(path + 'outputs/jobs39/SraRunTable.txt', sep='\\t')\n",
    "df_sra = df_sra.rename(columns={'Run':'#SampleID'})\n",
    "\n",
    "# insert in reverse order\n",
    "for i in keep:\n",
    "    df_sra.insert(1, i, ['NA' for _ in range(len(df_sra))])\n",
    "\n",
    "df_sra.to_csv(path + 'outputs/jobs39/qiime_mapping_file.tsv', sep='\\t')\n",
    "df_sra.columns.values\n",
    "# df_sra['Sample Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e694746-cbe0-44e7-985b-984fab532689",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### jobs44 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b3782fa4-6cfc-4e3b-8767-3addc65a9fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run title</th>\n",
       "      <th>BioProject accession</th>\n",
       "      <th>Experiment accession</th>\n",
       "      <th>Run data file type</th>\n",
       "      <th>Read filename 1</th>\n",
       "      <th>Read file1 MD5</th>\n",
       "      <th>DownLoad Read file1</th>\n",
       "      <th>Read filename 2</th>\n",
       "      <th>Read file2 MD5</th>\n",
       "      <th>DownLoad  Read file2</th>\n",
       "      <th>...</th>\n",
       "      <th>Reference file name</th>\n",
       "      <th>MD5 for reference file</th>\n",
       "      <th>Assembly Name or Accession</th>\n",
       "      <th>Assembly Accession URL</th>\n",
       "      <th>other_db</th>\n",
       "      <th>accession_in_other_db</th>\n",
       "      <th>other_db_url</th>\n",
       "      <th>DiagnosisOG</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>HostSubjectId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#SampleID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#q2:types</th>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRR442600</th>\n",
       "      <td>D8:Amplicon sequence of human fecal sample:pSS...</td>\n",
       "      <td>PRJCA008752</td>\n",
       "      <td>CRX385346</td>\n",
       "      <td>fastq</td>\n",
       "      <td>CRR442600_f1.fq.gz (12975507 bytes)</td>\n",
       "      <td>3149e0d5588d0cea4b58c1a2706c7e43</td>\n",
       "      <td>ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...</td>\n",
       "      <td>CRR442600_r2.fq.gz (12152647 bytes)</td>\n",
       "      <td>038b8b7280f629bba6e6fa50eb5b78f2</td>\n",
       "      <td>ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pSS patients without treament</td>\n",
       "      <td>SjD</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRR442603</th>\n",
       "      <td>D11:Amplicon sequence of human fecal sample:pS...</td>\n",
       "      <td>PRJCA008752</td>\n",
       "      <td>CRX385349</td>\n",
       "      <td>fastq</td>\n",
       "      <td>CRR442603_f1.fq.gz (10712320 bytes)</td>\n",
       "      <td>854db81c703df4130019c80e717ccad7</td>\n",
       "      <td>ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...</td>\n",
       "      <td>CRR442603_r2.fq.gz (10213484 bytes)</td>\n",
       "      <td>692bcab19cb7f412000af2869de5355f</td>\n",
       "      <td>ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pSS patients without treament</td>\n",
       "      <td>SjD</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRR442606</th>\n",
       "      <td>D14:Amplicon sequence of human fecal sample:pS...</td>\n",
       "      <td>PRJCA008752</td>\n",
       "      <td>CRX385352</td>\n",
       "      <td>fastq</td>\n",
       "      <td>CRR442606_f1.fq.gz (11509869 bytes)</td>\n",
       "      <td>aa3c4d14208bb22f40b7a1813fe5c4fc</td>\n",
       "      <td>ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...</td>\n",
       "      <td>CRR442606_r2.fq.gz (11022278 bytes)</td>\n",
       "      <td>49cdb6984acb61ce32e31d7851bf9468</td>\n",
       "      <td>ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pSS patients without treament</td>\n",
       "      <td>SjD</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRR442608</th>\n",
       "      <td>D16:Amplicon sequence of human fecal sample:pS...</td>\n",
       "      <td>PRJCA008752</td>\n",
       "      <td>CRX385354</td>\n",
       "      <td>fastq</td>\n",
       "      <td>CRR442608_f1.fq.gz (12899732 bytes)</td>\n",
       "      <td>6fb9bfd4498e608a33d0bfdcbbf32c48</td>\n",
       "      <td>ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...</td>\n",
       "      <td>CRR442608_r2.fq.gz (12309020 bytes)</td>\n",
       "      <td>8491d2cd4dfe9d639f256b307f459eda</td>\n",
       "      <td>ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pSS patients without treament</td>\n",
       "      <td>SjD</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Run title  \\\n",
       "#SampleID                                                      \n",
       "#q2:types                                        categorical   \n",
       "CRR442600  D8:Amplicon sequence of human fecal sample:pSS...   \n",
       "CRR442603  D11:Amplicon sequence of human fecal sample:pS...   \n",
       "CRR442606  D14:Amplicon sequence of human fecal sample:pS...   \n",
       "CRR442608  D16:Amplicon sequence of human fecal sample:pS...   \n",
       "\n",
       "          BioProject accession Experiment accession Run data file type  \\\n",
       "#SampleID                                                                \n",
       "#q2:types          categorical          categorical        categorical   \n",
       "CRR442600          PRJCA008752            CRX385346              fastq   \n",
       "CRR442603          PRJCA008752            CRX385349              fastq   \n",
       "CRR442606          PRJCA008752            CRX385352              fastq   \n",
       "CRR442608          PRJCA008752            CRX385354              fastq   \n",
       "\n",
       "                               Read filename 1  \\\n",
       "#SampleID                                        \n",
       "#q2:types                          categorical   \n",
       "CRR442600  CRR442600_f1.fq.gz (12975507 bytes)   \n",
       "CRR442603  CRR442603_f1.fq.gz (10712320 bytes)   \n",
       "CRR442606  CRR442606_f1.fq.gz (11509869 bytes)   \n",
       "CRR442608  CRR442608_f1.fq.gz (12899732 bytes)   \n",
       "\n",
       "                             Read file1 MD5  \\\n",
       "#SampleID                                     \n",
       "#q2:types                       categorical   \n",
       "CRR442600  3149e0d5588d0cea4b58c1a2706c7e43   \n",
       "CRR442603  854db81c703df4130019c80e717ccad7   \n",
       "CRR442606  aa3c4d14208bb22f40b7a1813fe5c4fc   \n",
       "CRR442608  6fb9bfd4498e608a33d0bfdcbbf32c48   \n",
       "\n",
       "                                         DownLoad Read file1  \\\n",
       "#SampleID                                                      \n",
       "#q2:types                                        categorical   \n",
       "CRR442600  ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...   \n",
       "CRR442603  ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...   \n",
       "CRR442606  ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...   \n",
       "CRR442608  ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...   \n",
       "\n",
       "                               Read filename 2  \\\n",
       "#SampleID                                        \n",
       "#q2:types                          categorical   \n",
       "CRR442600  CRR442600_r2.fq.gz (12152647 bytes)   \n",
       "CRR442603  CRR442603_r2.fq.gz (10213484 bytes)   \n",
       "CRR442606  CRR442606_r2.fq.gz (11022278 bytes)   \n",
       "CRR442608  CRR442608_r2.fq.gz (12309020 bytes)   \n",
       "\n",
       "                             Read file2 MD5  \\\n",
       "#SampleID                                     \n",
       "#q2:types                       categorical   \n",
       "CRR442600  038b8b7280f629bba6e6fa50eb5b78f2   \n",
       "CRR442603  692bcab19cb7f412000af2869de5355f   \n",
       "CRR442606  49cdb6984acb61ce32e31d7851bf9468   \n",
       "CRR442608  8491d2cd4dfe9d639f256b307f459eda   \n",
       "\n",
       "                                        DownLoad  Read file2  ...  \\\n",
       "#SampleID                                                     ...   \n",
       "#q2:types                                        categorical  ...   \n",
       "CRR442600  ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...  ...   \n",
       "CRR442603  ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...  ...   \n",
       "CRR442606  ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...  ...   \n",
       "CRR442608  ftp://download.big.ac.cn/gsa/CRA006415/CRR4426...  ...   \n",
       "\n",
       "          Reference file name MD5 for reference file  \\\n",
       "#SampleID                                              \n",
       "#q2:types         categorical            categorical   \n",
       "CRR442600                 NaN                    NaN   \n",
       "CRR442603                 NaN                    NaN   \n",
       "CRR442606                 NaN                    NaN   \n",
       "CRR442608                 NaN                    NaN   \n",
       "\n",
       "          Assembly Name or Accession Assembly Accession URL     other_db  \\\n",
       "#SampleID                                                                  \n",
       "#q2:types                categorical            categorical  categorical   \n",
       "CRR442600                        NaN                    NaN          NaN   \n",
       "CRR442603                        NaN                    NaN          NaN   \n",
       "CRR442606                        NaN                    NaN          NaN   \n",
       "CRR442608                        NaN                    NaN          NaN   \n",
       "\n",
       "          accession_in_other_db other_db_url                    DiagnosisOG  \\\n",
       "#SampleID                                                                     \n",
       "#q2:types           categorical  categorical                    categorical   \n",
       "CRR442600                   NaN          NaN  pSS patients without treament   \n",
       "CRR442603                   NaN          NaN  pSS patients without treament   \n",
       "CRR442606                   NaN          NaN  pSS patients without treament   \n",
       "CRR442608                   NaN          NaN  pSS patients without treament   \n",
       "\n",
       "             Diagnosis HostSubjectId  \n",
       "#SampleID                             \n",
       "#q2:types  categorical   categorical  \n",
       "CRR442600          SjD             8  \n",
       "CRR442603          SjD            11  \n",
       "CRR442606          SjD            14  \n",
       "CRR442608          SjD            16  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mapping file\n",
    "df = pd.read_csv(path + 'outputs/jobs44/gutonlyCRR.csv')\n",
    "df = df[df['Run title'].str.contains('fecal')]\n",
    "df = df.set_index('Accession')\n",
    "\n",
    "# get diagnosis column\n",
    "df['DiagnosisOG'] = df['Run title'].map(lambda x: x.split('sample:')[-1])\n",
    "\n",
    "# create new simplified one\n",
    "df = df[df['DiagnosisOG'].isin(['healthy control','pSS patients without treament'])]\n",
    "# pSS patients without treament            90\n",
    "# pSS patients with 3-6 month treament     46\n",
    "# non-pSS patient                          43\n",
    "# healthy control                          40\n",
    "# pSS patients with 6-12 month treament    11                       \n",
    "\n",
    "# create new diagnosis\n",
    "df['Diagnosis'] = df['DiagnosisOG'].map({'healthy control': 'HC', 'pSS patients without treament': 'SjD'})\n",
    "\n",
    "# create categorical\n",
    "df = df.reset_index()\n",
    "df.loc[-1] = ['categorical' for _ in range(len(df.columns))] # adding a row\n",
    "df.index = df.index + 1  # shifting index\n",
    "df.sort_index(inplace=True) \n",
    "df.iloc[0,0] = '#q2:types'\n",
    "df = df.set_index('Accession')\n",
    "df.index.name = '#SampleID'\n",
    "\n",
    "# create host subject id\n",
    "df['HostSubjectId'] = df['ID']\n",
    "\n",
    "# drop \"ID\" it is protected in QIIME\n",
    "df = df.drop('ID',axis=1)\n",
    "\n",
    "# export\n",
    "df.to_csv(path + 'outputs/jobs44/qiime_mapping_file.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffef5f0-0647-46e0-a41b-1cf2891be3f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Jobs 45 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "404bbcda-2a66-4c0d-8775-540f98daf284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "PsO            39\n",
       "HC             21\n",
       "categorical     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jobs45\n",
    "df = pd.read_csv(path + 'outputs/jobs45/SraRunTable.txt', sep='\\t')\n",
    "\n",
    "# create host subject ID col\n",
    "df['HostSubjectId'] = df['Run']\n",
    "df = df.set_index('Run')\n",
    "\n",
    "# get diagnosis column\n",
    "df['Diagnosis'] = df['Sample Name'].map(lambda x: 'PsO' if 'PSORI' in x else 'HC')\n",
    "\n",
    "# create categorical\n",
    "df = df.reset_index()\n",
    "df.loc[-1] = ['categorical' for _ in range(len(df.columns))] # adding a row\n",
    "df.index = df.index + 1  # shifting index\n",
    "df.sort_index(inplace=True) \n",
    "df.iloc[0,0] = '#q2:types'\n",
    "df = df.set_index('Run')\n",
    "df.index.name = '#SampleID'\n",
    "\n",
    "# export\n",
    "df.to_csv(path + 'outputs/jobs45/qiime_mapping_file.tsv', sep='\\t')\n",
    "\n",
    "# check breakdown\n",
    "df.Diagnosis.value_counts()\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9ab59-9452-4de3-90de-6cf605d46f90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### jobs46 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c2d4c87-be9d-427f-a839-6ed1bfa65407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "RA             26\n",
       "HC             26\n",
       "categorical     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jobs46\n",
    "df = pd.read_csv(path + 'outputs/jobs46/SraRunTable.txt', sep='\\t')\n",
    "\n",
    "# create host subject ID col\n",
    "df['HostSubjectId'] = df['Run']\n",
    "\n",
    "# df = df[df['Run title'].str.contains('fecal')]\n",
    "df = df.set_index('Run')\n",
    "\n",
    "# get diagnosis column\n",
    "df['Diagnosis'] = df['Sample Name'].map(lambda x: 'RA' if 'RA' in x else 'HC')\n",
    "\n",
    "# create categorical\n",
    "df = df.reset_index()\n",
    "df.loc[-1] = ['categorical' for _ in range(len(df.columns))] # adding a row\n",
    "df.index = df.index + 1  # shifting index\n",
    "df.sort_index(inplace=True) \n",
    "df.iloc[0,0] = '#q2:types'\n",
    "df = df.set_index('Run')\n",
    "df.index.name = '#SampleID'\n",
    "\n",
    "# export\n",
    "df.to_csv(path + 'outputs/jobs46/qiime_mapping_file.tsv', sep='\\t')\n",
    "\n",
    "    \n",
    "# check 26 HC 26 RA\n",
    "df.Diagnosis.value_counts()\n",
    "\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1fecc5-5d8c-4a93-a1fa-a60e8134438e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### jobs47 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1859f473-eff7-4d54-81a5-9eb9de50a6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "PsO            55\n",
       "HC             27\n",
       "categorical     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jobs47\n",
    "df = pd.read_csv(path + 'outputs/jobs47/SraRunTable.txt', sep='\\t')\n",
    "\n",
    "# create host subject ID col\n",
    "df['HostSubjectId'] = df['Run']\n",
    "\n",
    "# df = df[df['Run title'].str.contains('fecal')]\n",
    "df = df.set_index('Run')\n",
    "\n",
    "# get diagnosis column\n",
    "candidates = ['C' + str(x) for x in range(1,28)] # 27 healthy controls, C1...C27\n",
    "\n",
    "df['Diagnosis'] = df['Sample Name'].map(lambda x: 'HC' if x.split('_')[0] in candidates else 'PsO')\n",
    "\n",
    "# create categorical\n",
    "df = df.reset_index()\n",
    "df.loc[-1] = ['categorical' for _ in range(len(df.columns))] # adding a row\n",
    "df.index = df.index + 1  # shifting index\n",
    "df.sort_index(inplace=True) \n",
    "df.iloc[0,0] = '#q2:types'\n",
    "df = df.set_index('Run')\n",
    "df.index.name = '#SampleID'\n",
    "\n",
    "# export\n",
    "df.to_csv(path + 'outputs/jobs47/qiime_mapping_file.tsv', sep='\\t')\n",
    "\n",
    "# check\n",
    "df.Diagnosis.value_counts()\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc4470-f709-4f51-a567-dc68ac53852c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### jobs48 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a4d74a4-0a52-4141-9608-20ff2fee9bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "SLE            26\n",
       "HC             21\n",
       "categorical     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jobs48\n",
    "df = pd.read_csv(path + 'outputs/jobs48/SraRunTable.txt', sep='\\t')\n",
    "\n",
    "# create host subject ID col\n",
    "df['HostSubjectId'] = df['Run']\n",
    "\n",
    "# df = df[df['Run title'].str.contains('fecal')]\n",
    "df = df.set_index('Run')\n",
    "\n",
    "# get diagnosis column\n",
    "df['Diagnosis'] = df['Sample Name'].map(lambda x: 'SLE' if 'SF' in x else 'HC')\n",
    "\n",
    "# create categorical\n",
    "df = df.reset_index()\n",
    "df.loc[-1] = ['categorical' for _ in range(len(df.columns))] # adding a row\n",
    "df.index = df.index + 1  # shifting index\n",
    "df.sort_index(inplace=True) \n",
    "df.iloc[0,0] = '#q2:types'\n",
    "df = df.set_index('Run')\n",
    "df.index.name = '#SampleID'\n",
    "\n",
    "# export\n",
    "df.to_csv(path + 'outputs/jobs48/qiime_mapping_file.tsv', sep='\\t')\n",
    "\n",
    "# check\n",
    "df.Diagnosis.value_counts()\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f7cc3-d0c0-4388-91c3-a3a20c7ed890",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Jobs49 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5339cc3-5b72-4691-938c-ab2c4a79c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis\n",
      "at_risk        124\n",
      "HLT             22\n",
      "NORA             8\n",
      "categorical      1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Group</th>\n",
       "      <th>HostSubjectId</th>\n",
       "      <th>Timepoint</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#SampleID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categorical</th>\n",
       "      <td>#q2:types</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>at_risk</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>at_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>at_risk</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>at_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2</td>\n",
       "      <td>at_risk</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>at_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>3</td>\n",
       "      <td>at_risk</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>at_risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index        Group HostSubjectId    Timepoint    Diagnosis\n",
       "#SampleID                                                                  \n",
       "categorical  #q2:types  categorical   categorical  categorical  categorical\n",
       "13                   0      at_risk            13            1      at_risk\n",
       "168                  1      at_risk           168            1      at_risk\n",
       "172                  2      at_risk           172            1      at_risk\n",
       "188                  3      at_risk           188            1      at_risk"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jobs49\n",
    "df = pd.read_csv(path + 'outputs/jobs49/metadata_kb.txt', sep='\\t')\n",
    "\n",
    "# drop random na rows\n",
    "df = df.dropna()\n",
    "\n",
    "# dictionary\n",
    "# CCP   at- risk individual \n",
    "# NORA\tnew onset RA \n",
    "# HLT \tHealthy individual\n",
    "# NG-XXX-XX\tLongitudinal study-particiapnt number-timepoint\n",
    "\n",
    "# create host subject ID col\n",
    "df['HostSubjectId'] = df['sample_id'].apply(lambda x: x.split('-')[1] if 'NG' in x else x)\n",
    "\n",
    "# create timepoint column\n",
    "df['Timepoint'] = df['sample_id'].apply(lambda x: x.split('-')[-1] if 'NG' in x else 1)\n",
    "                                                            \n",
    "# probably will keep only first timepoint\n",
    "df = df.drop_duplicates(subset='HostSubjectId', keep='first', inplace=False)\n",
    "\n",
    "# # get diagnosis column\n",
    "df['Diagnosis'] = df['Group']\n",
    "\n",
    "# create categorical\n",
    "df = df.reset_index()\n",
    "df.loc[-1] = ['categorical' for _ in range(len(df.columns))] # adding a row\n",
    "df.index = df.index + 1  # shifting index\n",
    "df.sort_index(inplace=True) \n",
    "df.iloc[0,0] = '#q2:types'\n",
    "df = df.set_index('sample_id')\n",
    "df.index.name = '#SampleID'\n",
    "\n",
    "# export\n",
    "df.to_csv(path + 'outputs/jobs49/qiime_mapping_file.tsv', sep='\\t')\n",
    "\n",
    "# check\n",
    "print(df.Diagnosis.value_counts())\n",
    "# df.sample_id.values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a82520-aae9-4130-abe5-90e6a8b9486c",
   "metadata": {},
   "source": [
    "##### Alpha ##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2938f730-756f-4309-85af-87c6467715f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide what to analyze\n",
    "keep = ['SjD','HC','SLE','SLE-G','RA','PsO']#,'axial spondyloarthritis']\n",
    "jobs = ['jobs41','jobs44', 'jobs45', 'jobs46','jobs49']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cabf431-d811-4734-931e-bf39cc8bc4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>cohort</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518-0-twin-psa-plate308</th>\n",
       "      <td>PsO</td>\n",
       "      <td>5.983555</td>\n",
       "      <td>AMPAIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524-0-twin-psa-plate308</th>\n",
       "      <td>PsO</td>\n",
       "      <td>4.126833</td>\n",
       "      <td>AMPAIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525-0-twin-psa-plate308</th>\n",
       "      <td>PsO</td>\n",
       "      <td>5.451687</td>\n",
       "      <td>AMPAIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528-0-twin-psa-plate308</th>\n",
       "      <td>PsO</td>\n",
       "      <td>4.153750</td>\n",
       "      <td>AMPAIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529-0-twin-psa-plate308</th>\n",
       "      <td>PsO</td>\n",
       "      <td>4.034945</td>\n",
       "      <td>AMPAIM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Diagnosis  shannon_entropy  cohort\n",
       "id                                                        \n",
       "518-0-twin-psa-plate308       PsO         5.983555  AMPAIM\n",
       "524-0-twin-psa-plate308       PsO         4.126833  AMPAIM\n",
       "525-0-twin-psa-plate308       PsO         5.451687  AMPAIM\n",
       "528-0-twin-psa-plate308       PsO         4.153750  AMPAIM\n",
       "529-0-twin-psa-plate308       PsO         4.034945  AMPAIM"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha plots\n",
    "for alpha_metric in ['shannon_entropy']:#, 'faith_pd']:\n",
    "    # create list of dfs to concat\n",
    "    dfs = []\n",
    "\n",
    "    # for q2 mapping\n",
    "    df = pd.read_csv(path + 'inputs/Q2_MSQ138_141_noctrl_noeiser_nocd_correct_new/' + alpha_metric + '_metadata.tsv', sep='\\t')\n",
    "    df = df.set_index('id')\n",
    "    df = df.drop('#q2:types')\n",
    "\n",
    "    # create cohort and do replacements\n",
    "    df['cohort'] = 'AMPAIM'\n",
    "    df = df.replace(sub_dict)\n",
    "\n",
    "    # keep things only in consideratino\n",
    "    df = df[df['Diagnosis'].isin(keep)]\n",
    "        \n",
    "    dfs.append(df)\n",
    "    \n",
    "    for job in jobs:\n",
    "        # load df\n",
    "        df = pd.read_csv(path + 'outputs/' + job + '/Analysis_core_pipeline_taxonomic_0/diversity/' + alpha_metric + '_metadata.tsv', sep='\\t')\n",
    "    \n",
    "        # rename\n",
    "        df = df.rename(columns={'host_disease':'Diagnosis'})\n",
    "    \n",
    "        # replace\n",
    "        df = df.replace(sub_dict)\n",
    "        \n",
    "        # q2 modifications\n",
    "        df = df.set_index('id')\n",
    "        df = df.drop('#q2:types')\n",
    "    \n",
    "        # set cohort\n",
    "        df['cohort'] = j_to_res[job]['Cohort']\n",
    "    \n",
    "        # append to list\n",
    "        dfs.append(df)\n",
    "    \n",
    "    df_merge = pd.concat(dfs)\n",
    "    df_merge = df_merge.dropna(how='any',axis=1)\n",
    "    \n",
    "    df_merge[alpha_metric] = df_merge[alpha_metric].astype(float)\n",
    "    \n",
    "    # filter\n",
    "    df_merge = df_merge[df_merge['Diagnosis'].isin(keep)]\n",
    "\n",
    "    # export\n",
    "    df_merge.to_csv(path + 'outputs/jobs99/df_alpha_' + alpha_metric + '.tsv', sep='\\t')\n",
    "\n",
    "    # draw figure    \n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.boxplot(data=df_merge,x='cohort',y=alpha_metric,hue='Diagnosis',showfliers=False)\n",
    "    #sns.stripplot(data=df_merge,x='cohort',y='shannon_entropy',hue='Diagnosis',legend=None,dodge=True,color='gray')\n",
    "    sns.despine()\n",
    "    plt.savefig(path + 'outputs/jobs99/alpha_meta_' + alpha_metric + '.pdf')\n",
    "    plt.close()\n",
    "#  plt.tight_layout()\n",
    "\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96789aa2-cda4-4b3a-8b50-b62b2ddf906f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group 1</th>\n",
       "      <th>Group 2</th>\n",
       "      <th>Sample size</th>\n",
       "      <th>Permutations</th>\n",
       "      <th>pseudo-F</th>\n",
       "      <th>p-value</th>\n",
       "      <th>q-value</th>\n",
       "      <th>cohort</th>\n",
       "      <th>-log10p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HC</td>\n",
       "      <td>PsO</td>\n",
       "      <td>35</td>\n",
       "      <td>999</td>\n",
       "      <td>1.001743</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.446</td>\n",
       "      <td>Rooney2024</td>\n",
       "      <td>0.350665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group 1 Group 2  Sample size  Permutations  pseudo-F  p-value  q-value  \\\n",
       "25      HC     PsO           35           999  1.001743    0.446    0.446   \n",
       "\n",
       "        cohort   -log10p  \n",
       "25  Rooney2024  0.350665  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge[df_merge['cohort'] == 'Rooney2024']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6848f-6767-4ec5-a2ba-5b33baf834e1",
   "metadata": {},
   "source": [
    "##### Beta #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc4c1937-69a1-4e52-8376-9d3ae1ec1bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs41\n",
      "Su2020\n",
      "jobs44\n",
      "Wang2022\n",
      "jobs45\n",
      "Luca2024\n",
      "jobs46\n",
      "Yu2022\n",
      "jobs49\n",
      "Rooney2024\n",
      "0\n",
      "checking\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group 1</th>\n",
       "      <th>Group 2</th>\n",
       "      <th>Sample size</th>\n",
       "      <th>Permutations</th>\n",
       "      <th>pseudo-F</th>\n",
       "      <th>p-value</th>\n",
       "      <th>q-value</th>\n",
       "      <th>cohort</th>\n",
       "      <th>-log10p</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HC</td>\n",
       "      <td>RA</td>\n",
       "      <td>50</td>\n",
       "      <td>999</td>\n",
       "      <td>1.349725</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>AMPAIM</td>\n",
       "      <td>0.995679</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HC</td>\n",
       "      <td>PsO</td>\n",
       "      <td>34</td>\n",
       "      <td>999</td>\n",
       "      <td>1.397645</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>AMPAIM</td>\n",
       "      <td>1.086186</td>\n",
       "      <td>PsO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HC</td>\n",
       "      <td>SLE</td>\n",
       "      <td>11</td>\n",
       "      <td>999</td>\n",
       "      <td>1.192808</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.3640</td>\n",
       "      <td>AMPAIM</td>\n",
       "      <td>0.681937</td>\n",
       "      <td>SLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HC</td>\n",
       "      <td>SjD</td>\n",
       "      <td>16</td>\n",
       "      <td>999</td>\n",
       "      <td>1.548308</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>AMPAIM</td>\n",
       "      <td>1.275724</td>\n",
       "      <td>SjD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HC</td>\n",
       "      <td>SLE</td>\n",
       "      <td>37</td>\n",
       "      <td>999</td>\n",
       "      <td>8.483951</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>Su2020</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>SLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group 1 Group 2  Sample size  Permutations  pseudo-F  p-value  q-value  \\\n",
       "0       HC      RA           50           999  1.349725    0.101   0.2380   \n",
       "4       HC     PsO           34           999  1.397645    0.082   0.2380   \n",
       "5       HC     SLE           11           999  1.192808    0.208   0.3640   \n",
       "6       HC     SjD           16           999  1.548308    0.053   0.2380   \n",
       "11      HC     SLE           37           999  8.483951    0.001   0.0015   \n",
       "\n",
       "    cohort   -log10p Diagnosis  \n",
       "0   AMPAIM  0.995679        RA  \n",
       "4   AMPAIM  1.086186       PsO  \n",
       "5   AMPAIM  0.681937       SLE  \n",
       "6   AMPAIM  1.275724       SjD  \n",
       "11  Su2020  3.000000       SLE  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beta plots\n",
    "dfs = []\n",
    "# ampaim\n",
    "df = pd.read_csv(path + 'inputs/Q2_MSQ138_141_noctrl_noeiser_nocd_correct_new/permanova-pairwise.csv')\n",
    "df['cohort'] = 'AMPAIM'\n",
    "df = df.replace(sub_dict)\n",
    "df = df[df['Group 1'].isin(keep)]\n",
    "df = df[df['Group 2'].isin(keep)]\n",
    "df['comparison'] = df['Group 1'] + '_' + df['Group 2']\n",
    "dfs.append(df)\n",
    "# validation\n",
    "for job in jobs:\n",
    "    print(job)\n",
    "    # load df\n",
    "    df = pd.read_csv(path + 'outputs/' + job + '/Analysis_core_pipeline_taxonomic_0/diversity/permanova-pairwise.csv')\n",
    "    \n",
    "    # set cohort\n",
    "    df['cohort'] = j_to_res[job]['Cohort']\n",
    "    print(j_to_res[job]['Cohort'])\n",
    "\n",
    "    # replace\n",
    "    df = df.replace(sub_dict)\n",
    "    \n",
    "    # append to list\n",
    "    dfs.append(df)\n",
    "\n",
    "df_merge = pd.concat(dfs)\n",
    "df_merge.index = [i for i in range(len(df_merge))]\n",
    "df_merge = df_merge.dropna(how='any',axis=1)\n",
    "\n",
    "# swap group2 HC with group1\n",
    "# df_merge_final = df_merge.copy()\n",
    "for i,row in df_merge.iterrows():\n",
    "    print(i)\n",
    "    if row.iloc[1] == 'HC':\n",
    "        print('checking')\n",
    "        temp = row.iloc[0]\n",
    "        #print(temp)\n",
    "        df_merge.iloc[i, 0] = 'HC'\n",
    "        df_merge.iloc[i, 1] = temp\n",
    "\n",
    "# df_merge['shannon_entropy'] = df_merge['shannon_entropy'].astype(float)\n",
    "\n",
    "# filter\n",
    "#keep = ['PsA','HC','SLE','SLE+G','SLE-G','RA','axial spondyloarthritis']\n",
    "#df_merge = df_merge[df_merge['Diagnosis'].isin(keep)]\n",
    "\n",
    "df_merge['-log10p'] = -1 * np.log10(df_merge['p-value'])\n",
    "df_merge['Group 1'] = df_merge['Group 1'].replace(sub_dict)\n",
    "df_merge['Group 2'] = df_merge['Group 2'].replace(sub_dict)\n",
    "\n",
    "\n",
    "df = df_merge[df_merge['Group 1'] == 'HC']\n",
    "\n",
    "\n",
    "df = df[df['Group 1'].isin(keep)]\n",
    "df = df[df['Group 2'].isin(keep)]\n",
    "df['Diagnosis'] = df['Group 2']\n",
    "\n",
    "# save for R\n",
    "df.to_csv(path + 'outputs/jobs99/df_beta.tsv', sep='\\t')\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(data=df,x='cohort',y='-log10p',hue='Diagnosis')#,showfliers=False)\n",
    "sns.despine()\n",
    "plt.savefig(path + 'outputs/jobs99/beta_permanova_pvals.pdf')\n",
    "plt.close()\n",
    "#sns.despine()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ddb223-d29b-4437-8580-207eb49cfa39",
   "metadata": {},
   "source": [
    "##### LEfSe #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56f1a186-85f8-46fb-b4de-cae6e3ddb097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: f__Rikenellaceae\n",
      "jobs41\n",
      "11\n",
      "Diagnosis\n",
      "SLE+G    20\n",
      "HC       20\n",
      "SLE      17\n",
      "Name: count, dtype: int64\n",
      "jobs44\n",
      "13\n",
      "Diagnosis\n",
      "SjD    63\n",
      "HC     24\n",
      "Name: count, dtype: int64\n",
      "jobs45\n",
      "11\n",
      "Diagnosis\n",
      "PsO    39\n",
      "HC     21\n",
      "Name: count, dtype: int64\n",
      "jobs46\n",
      "7\n",
      "Diagnosis\n",
      "RA    26\n",
      "HC    26\n",
      "Name: count, dtype: int64\n",
      "jobs49\n",
      "8\n",
      "Diagnosis\n",
      "PsO    26\n",
      "HC      9\n",
      "Name: count, dtype: int64\n",
      "query: g__Phasco\n",
      "jobs41\n",
      "4\n",
      "Diagnosis\n",
      "SLE+G    20\n",
      "HC       20\n",
      "SLE      17\n",
      "Name: count, dtype: int64\n",
      "jobs44\n",
      "6\n",
      "Diagnosis\n",
      "SjD    63\n",
      "HC     24\n",
      "Name: count, dtype: int64\n",
      "jobs45\n",
      "5\n",
      "Diagnosis\n",
      "PsO    39\n",
      "HC     21\n",
      "Name: count, dtype: int64\n",
      "jobs46\n",
      "4\n",
      "Diagnosis\n",
      "RA    26\n",
      "HC    26\n",
      "Name: count, dtype: int64\n",
      "jobs49\n",
      "1\n",
      "Diagnosis\n",
      "PsO    26\n",
      "HC      9\n",
      "Name: count, dtype: int64\n",
      "query: g__Prevotella\n",
      "jobs41\n",
      "15\n",
      "Diagnosis\n",
      "SLE+G    20\n",
      "HC       20\n",
      "SLE      17\n",
      "Name: count, dtype: int64\n",
      "jobs44\n",
      "55\n",
      "Diagnosis\n",
      "SjD    63\n",
      "HC     24\n",
      "Name: count, dtype: int64\n",
      "jobs45\n",
      "14\n",
      "Diagnosis\n",
      "PsO    39\n",
      "HC     21\n",
      "Name: count, dtype: int64\n",
      "jobs46\n",
      "14\n",
      "Diagnosis\n",
      "RA    26\n",
      "HC    26\n",
      "Name: count, dtype: int64\n",
      "jobs49\n",
      "7\n",
      "Diagnosis\n",
      "PsO    26\n",
      "HC      9\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>taxa</th>\n",
       "      <th>MWU</th>\n",
       "      <th>MWU_p</th>\n",
       "      <th>ttest</th>\n",
       "      <th>ttest_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job, taxa, MWU, MWU_p, ttest, ttest_p]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# automatic parsing of pairwise lefses for queries\n",
    "import itertools\n",
    "# list(itertools.combinations(['A','B','C'], 2))\n",
    "\n",
    "jobns = []\n",
    "taxas = []\n",
    "mwus = []\n",
    "mwups = []\n",
    "tts = []\n",
    "ttps = []\n",
    "\n",
    "\n",
    "# dict to store resluts\n",
    "q_to_t = {}\n",
    "queries = ['f__Rikenellaceae', 'g__Phasco','g__Prevotella']\n",
    "# queries = ['f__Tannerell','g__Parabacter']\n",
    "# queries = [x.replace('.','|') for x in LDAnan]\n",
    "#queries = [x.replace('__','protect') for x in queries]\n",
    "#queries = [x.replace('_','-') for x in queries]\n",
    "#queries = [x.replace('protect','__') for x in queries]\n",
    "\n",
    "\n",
    "\n",
    "# do MWU on each col and the aggregate\n",
    "for q in queries:\n",
    "    print('query: ' + q)\n",
    "\n",
    "    # compile dfs \n",
    "    dfs = []\n",
    "    for job in jobs:\n",
    "        print(job)\n",
    "        if 'jobs4' in job:\n",
    "            df = pd.read_csv(path + 'outputs/' + job + '/Analysis_lefse_0/tables/Diagnosis/lefse_format.taxa_table_L7.Diagnosis.NA.tsv', \n",
    "                             sep='\\t', \n",
    "                             header=None)\n",
    "        else:\n",
    "            # for AMPAIM jobs\n",
    "            df = pd.read_csv(path + 'outputs/' + job + '/lefse_table.tsv', \n",
    "                             sep='\\t',\n",
    "                             header=None)\n",
    "        df = df.T\n",
    "        df.columns = df.iloc[0,:]\n",
    "        df = df.drop(0) # drops the row of col names\n",
    "        df = df.iloc[:,1:] # drops one of the Diagnosis cols\n",
    "                \n",
    "        # rename dx\n",
    "        # df = df.rename(columns=dx_sub_dict)\n",
    "                \n",
    "        df['SampleID'] = job + '_' + df['HostSubjectId'] + '_' + df['Diagnosis'].replace(sub_dict)\n",
    "        df = df.drop(['Diagnosis','HostSubjectId'], axis=1)\n",
    "        df = df.set_index('SampleID')\n",
    "\n",
    "        \n",
    "        # normalize columns\n",
    "        df = df.astype(float)\n",
    "        df = df.div(df.sum(axis=1),axis=0)\n",
    "        \n",
    "        # put back diagnosis col\n",
    "        df['Diagnosis'] = df.index.map(lambda x: x.split('_')[-1])\n",
    "\n",
    "        # if AMPAIM job not jobs09, drop the healthy samples\n",
    "        if job in ['jobs10','jobs11','jobs12','jobs13','jobs14']:\n",
    "            df = df[df['Diagnosis'] != 'HC']\n",
    "        \n",
    "        # find relevant taxa to the query\n",
    "        int_taxa = []\n",
    "        for f in df.columns.values:\n",
    "            if q in f:\n",
    "                # print(f)\n",
    "                int_taxa.append(f)\n",
    "        print(len(int_taxa))\n",
    "            \n",
    "        # subset on taxa of interest\n",
    "        df_sub = df[int_taxa] \n",
    "        \n",
    "        # create new total 'collapsed genus'\n",
    "        df_sub['total_' + q] = df_sub.sum(axis=1)\n",
    "        \n",
    "        # bring back Diagnosis column\n",
    "        df_sub['Diagnosis'] = df['Diagnosis']\n",
    "        \n",
    "        # make cohort col\n",
    "        df_sub['Cohort'] = j_to_res[job]['Cohort']\n",
    "\n",
    "        #\n",
    "        print(df_sub.Diagnosis.value_counts())\n",
    "        # add to list of dfs\n",
    "        dfs.append(df_sub)\n",
    "\n",
    "    # create big df\n",
    "    df_sub = pd.concat(dfs)\n",
    "\n",
    "    # for the taxa\n",
    "    for t in df_sub.columns:\n",
    "        if '__' in t:\n",
    "            diagnoses = df_sub['Diagnosis'].unique()\n",
    "            \n",
    "            # do all pairwise combos\n",
    "            # for pair in list(itertools.combinations(diagnoses, 2)):\n",
    "            #     d0, d1 = pair\n",
    "            #     #print(t)\n",
    "            #     #print(d0,d1)\n",
    "            #     df_d0 = df_sub[df_sub['Diagnosis'] == d0]\n",
    "            #     df_d1 = df_sub[df_sub['Diagnosis'] == d1]\n",
    "            #     u,p1 = scipy.stats.mannwhitneyu(df_d0[t],df_d1[t])\n",
    "            #     #print('MWU: u=' + str(np.round(u,2)) + ', p=' + str(np.round(p1,3)))\n",
    "            #     r,p2 = scipy.stats.ttest_ind(df_d0[t],df_d1[t])\n",
    "            #     #print('TT: t=' + str(np.round(r,2)) + ', p=' + str(np.round(p2,3)))\n",
    "            #     #print('\\n')\n",
    "            #     jobns.append(job)\n",
    "            #     taxas.append(t)\n",
    "            #     mwus.append(u)\n",
    "            #     mwups.append(p1)\n",
    "            #     tts.append(r)\n",
    "            #     ttps.append(p2)\n",
    "        \n",
    "            #     plt.figure(figsize=(4,3))\n",
    "            #     sns.boxplot(data=df_sub, x='Diagnosis', y=t, showfliers=False)\n",
    "            #     sns.stripplot(data=df_sub, x='Diagnosis', y=t,legend=None)\n",
    "            #     plt.tight_layout()\n",
    "            #     sns.despine()\n",
    "            #     plt.savefig(path + 'outputs/jobs100/plots/' + d0 + '_' + d1 + '_' + t + '.pdf')\n",
    "            #     plt.close()\n",
    "        \n",
    "            # boxplot across all studies\n",
    "            plt.figure(figsize=(8,6))\n",
    "            sns.boxplot(data=df_sub, x='Cohort',hue='Diagnosis', y=t, showfliers=False)\n",
    "            # sns.stripplot(data=df_sub, x='Cohort', hue='Diagnosis', y=t,legend=None)\n",
    "            plt.tight_layout()\n",
    "            sns.despine()\n",
    "            plt.savefig(path + 'outputs/jobs100/plots/all_' + t.split('f__')[-1] + '.pdf')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "df_ref = pd.DataFrame({'job': jobns, 'taxa': taxas, 'MWU': mwus, 'MWU_p': mwups, 'ttest': tts, 'ttest_p': ttps})\n",
    "df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741e46b-a4b4-478f-9931-923867cc5d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
